{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "chatbot.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyO+XEPZBSBcOh6VSx/8Gekk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dilanbakr/chatbot/blob/main/chatbot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vn5oxt-P0KnJ"
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fFLa21x00nyJ"
      },
      "source": [
        "from keras.models import Sequential, Model\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.layers import Input, Activation, Dense, LSTM, Permute, Dropout, BatchNormalization, add, dot, concatenate\n",
        "from keras.utils.data_utils import get_file\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.optimizers import Adam\n",
        "from functools import reduce\n",
        "import tarfile\n",
        "import numpy as np\n",
        "import re"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Qd81fHM0xAu"
      },
      "source": [
        "def tokenize(sent): ## splitting the text in tokens including punctuation\n",
        "    return [x.strip() for x in re.split('(\\W+)?', sent) if x.strip()]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NHymg6HV2hpN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39be02cc-94f4-4b42-c3a8-da804a611cfb"
      },
      "source": [
        " a = tokenize(\"  jjhb ıhbjb, şojışk knk. \")\n",
        " a"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.6/re.py:212: FutureWarning: split() requires a non-empty pattern match.\n",
            "  return _compile(pattern, flags).split(string, maxsplit)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['jjhb', 'ıhbjb', ',', 'şojışk', 'knk', '.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4kqVyVoE2pEz"
      },
      "source": [
        "#Parse stories provided in the bAbi tasks format\n",
        "#If only_supporting is true, only the sentences\n",
        "#that support the answer are kept.\n",
        "def parse_stories(lines, only_supporting=False):\n",
        "    data = []\n",
        "    story = []\n",
        "    for line in lines:\n",
        "        line = line.decode('utf-8').strip()\n",
        "        id, line = line.split(' ', 1)\n",
        "        id = int(id)\n",
        "        if id == 1:\n",
        "            story = []\n",
        "        if '\\t' in line:\n",
        "            q, a, supporting = line.split('\\t')\n",
        "            q = tokenize(q)\n",
        "            substory = None\n",
        "            if only_supporting:\n",
        "                # Only select the related substory\n",
        "                supporting = map(int, supporting.split())\n",
        "                substory = [story[i - 1] for i in supporting]\n",
        "            else:\n",
        "                # Provide all the substories\n",
        "                substory = [x for x in story if x]\n",
        "            data.append((substory, q, a))\n",
        "            story.append('')\n",
        "        else:\n",
        "            sent = tokenize(line)\n",
        "            story.append(sent)\n",
        "    return data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kwzZrMEQ6I-g"
      },
      "source": [
        "#Given a file, read the file, retrieve the stories,\n",
        "#and then convert the sentences into a single story.\n",
        "#If max_length is supplied, any stories longer than max_length tokens will be discarded.\n",
        "def get_stories(file, only_supporting=False, max_length=None):\n",
        "    data = parse_stories(file.readlines(), only_supporting=only_supporting)\n",
        "    flat = lambda data: reduce(lambda i, j: i + j, data)\n",
        "    data = [(flat(story), question, answer) for story, question, answer in data if not max_length or len(flat(story)) < max_length]\n",
        "    return data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XFd40Ew26QHp"
      },
      "source": [
        "#Given a file, read the file, retrieve the stories,\n",
        "#and then convert the sentences into a single story.\n",
        "#If max_length is supplied, any stories longer than max_length tokens will be discarded.\n",
        "def get_stories(file, only_supporting=False, max_length=None):\n",
        "    data = parse_stories(file.readlines(), only_supporting=only_supporting)\n",
        "    flat = lambda data: reduce(lambda i, j: i + j, data)\n",
        "    data = [(flat(story), question, answer) for story, question, answer in data if not max_length or len(flat(story)) < max_length]\n",
        "    return data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "itljxCz06X0U"
      },
      "source": [
        "def vectorize_stories(data, word_id, story_maxlen, question_maxlen):\n",
        "    X = []\n",
        "    Q = []\n",
        "    Y = []\n",
        "    for story, question, answer in data:\n",
        "        x = [word_id[i] for i in story]\n",
        "        q = [word_id[i] for i in question]\n",
        "        # Index 0 is reserved\n",
        "        y = np.zeros(len(word_id) + 1)\n",
        "        y[word_id[answer]] = 1\n",
        "        X.append(x)\n",
        "        Q.append(q)\n",
        "        Y.append(y)\n",
        "    return (pad_sequences(X, maxlen=story_maxlen), pad_sequences(Q, maxlen=question_maxlen), np.array(Y))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7_LH8ny76tZ6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "840f51ac-7aa5-45eb-91c2-bff3dd0dc843"
      },
      "source": [
        "tar_file = tarfile.open(get_file('babi-tasks-v1-2.tar.gz',\n",
        "                                 origin='https://s3.amazonaws.com/text-datasets/babi_tasks_1-20_v1-2.tar.gz'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/text-datasets/babi_tasks_1-20_v1-2.tar.gz\n",
            "11747328/11745123 [==============================] - 2s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B6DVqAuc6xr3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c800932-59e6-4256-aa37-18fc57a7034a"
      },
      "source": [
        "challenges = {\n",
        "    'single_supporting_fact_10k': 'tasks_1-20_v1-2/en-10k/qa1_single-supporting-fact_{}.txt', # QA1 with 10,000 samples\n",
        "    'two_supporting_facts_10k': 'tasks_1-20_v1-2/en-10k/qa2_two-supporting-facts_{}.txt', # QA2 with 10,000 samples\n",
        "}\n",
        "challenge_type = 'single_supporting_fact_10k'\n",
        "challenge = challenges[challenge_type]\n",
        "\n",
        "train_stories = get_stories(tar_file.extractfile(challenge.format('train')))\n",
        "test_stories = get_stories(tar_file.extractfile(challenge.format('test')))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.6/re.py:212: FutureWarning: split() requires a non-empty pattern match.\n",
            "  return _compile(pattern, flags).split(string, maxsplit)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f4L7HG1363nM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ff8c11f-ac25-4239-aa0b-6cd7defa0945"
      },
      "source": [
        "print('Train stories lenght:', len(train_stories))\n",
        "print('Test stories lenght:', len(test_stories))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train stories lenght: 10000\n",
            "Test stories lenght: 1000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OrJJpjNv7NVG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55e8d0d2-a263-47ef-d1b8-226aa883fb6f"
      },
      "source": [
        "train_stories[1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['Mary',\n",
              "  'moved',\n",
              "  'to',\n",
              "  'the',\n",
              "  'bathroom',\n",
              "  '.',\n",
              "  'John',\n",
              "  'went',\n",
              "  'to',\n",
              "  'the',\n",
              "  'hallway',\n",
              "  '.',\n",
              "  'Daniel',\n",
              "  'went',\n",
              "  'back',\n",
              "  'to',\n",
              "  'the',\n",
              "  'hallway',\n",
              "  '.',\n",
              "  'Sandra',\n",
              "  'moved',\n",
              "  'to',\n",
              "  'the',\n",
              "  'garden',\n",
              "  '.'],\n",
              " ['Where', 'is', 'Daniel', '?'],\n",
              " 'hallway')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dhmv-1Js7PXe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "174fc550-fe93-4ff8-95f1-cdc29de39f56"
      },
      "source": [
        "test_stories[1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['John',\n",
              "  'travelled',\n",
              "  'to',\n",
              "  'the',\n",
              "  'hallway',\n",
              "  '.',\n",
              "  'Mary',\n",
              "  'journeyed',\n",
              "  'to',\n",
              "  'the',\n",
              "  'bathroom',\n",
              "  '.',\n",
              "  'Daniel',\n",
              "  'went',\n",
              "  'back',\n",
              "  'to',\n",
              "  'the',\n",
              "  'bathroom',\n",
              "  '.',\n",
              "  'John',\n",
              "  'moved',\n",
              "  'to',\n",
              "  'the',\n",
              "  'bedroom',\n",
              "  '.'],\n",
              " ['Where', 'is', 'Mary', '?'],\n",
              " 'bathroom')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gv5tilwB8KXm"
      },
      "source": [
        "vocab = set()\n",
        "for story, question, answer in train_stories + test_stories:\n",
        "    vocab |= set(story + question + [answer])\n",
        "vocab = sorted(vocab)\n",
        "#print(vocab)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PUnmY_Xi-a6T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5925246-bc67-4100-c7e9-1ddb69e850f7"
      },
      "source": [
        "# Reserve 0 for masking via pad_sequences\n",
        "vocab_size = len(vocab) + 1\n",
        "vocab_size"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "22"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TBEVRbLf-fY1"
      },
      "source": [
        "story_maxlen = max(map(len, (s for s, _, _ in train_stories + test_stories)))\n",
        "question_maxlen = max(map(len, (s for _, s, _ in train_stories + test_stories)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i3spdBAI_CLs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "918b6f75-68f6-40bf-a9a9-5734b8afa274"
      },
      "source": [
        "print('Story max length:', story_maxlen)\n",
        "print('Question max length:', question_maxlen)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Story max length: 68\n",
            "Question max length: 4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qZkFqy3v_Si6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "650b13e2-ccc6-4b2e-ba33-eec3a69e1825"
      },
      "source": [
        "word2id = dict((w, i + 1) for i, w in enumerate(vocab))\n",
        "print(word2id)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'.': 1, '?': 2, 'Daniel': 3, 'John': 4, 'Mary': 5, 'Sandra': 6, 'Where': 7, 'back': 8, 'bathroom': 9, 'bedroom': 10, 'garden': 11, 'hallway': 12, 'is': 13, 'journeyed': 14, 'kitchen': 15, 'moved': 16, 'office': 17, 'the': 18, 'to': 19, 'travelled': 20, 'went': 21}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fxflCO8i_YKs"
      },
      "source": [
        "inputs_train, questions_train, answers_train = vectorize_stories(train_stories, word2id, story_maxlen, question_maxlen)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bt8IRQLZ_tq3"
      },
      "source": [
        "inputs_test, questions_test, answers_test = vectorize_stories(test_stories, word2id, story_maxlen, question_maxlen)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G4pxNrCjBI2I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2af1acfc-08f6-4891-820b-bb4e54eae253"
      },
      "source": [
        "print('inputs_train shape:', inputs_train.shape)\n",
        "print('inputs_test shape:', inputs_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "inputs_train shape: (10000, 68)\n",
            "inputs_test shape: (1000, 68)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hk-sEKQ-BLAn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da14968f-da2d-4c64-b78d-dc22b8c35008"
      },
      "source": [
        "print('queries_train shape:', questions_train.shape)\n",
        "print('queries_test shape:', questions_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "queries_train shape: (10000, 4)\n",
            "queries_test shape: (1000, 4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GqPXKmflBq66",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8379f1cc-a7f2-451b-e32a-803c67648a2c"
      },
      "source": [
        "print('answers_train shape:', answers_train.shape)\n",
        "print('answers_test shape:', answers_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "answers_train shape: (10000, 22)\n",
            "answers_test shape: (1000, 22)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PCtJa1mpBtrr"
      },
      "source": [
        "story_sequence = Input((story_maxlen,))\n",
        "question = Input((question_maxlen,))\n",
        "\n",
        "# embed the input sequence into a sequence of vectors for the stories\n",
        "input_encoder_s = Sequential()\n",
        "input_encoder_s.add(Embedding(input_dim=vocab_size, output_dim=64))\n",
        "input_encoder_s.add(Dropout(0.3))\n",
        "\n",
        "# embed the input into a sequence of vectors of size question_maxlen\n",
        "# output: (samples, story_maxlen, question_maxlen)\n",
        "input_encoder_q = Sequential()\n",
        "input_encoder_q.add(Embedding(input_dim=vocab_size, output_dim=question_maxlen))\n",
        "input_encoder_q.add(Dropout(0.3))\n",
        "\n",
        "# embed the question into a sequence of vectors\n",
        "question_encoder = Sequential()\n",
        "question_encoder.add(Embedding(input_dim=vocab_size, output_dim=64, input_length=question_maxlen))\n",
        "question_encoder.add(Dropout(0.3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bkdRxH-xDc-M"
      },
      "source": [
        "# encode input sequence and questions to sequences of dense vectors\n",
        "input_encoded_s = input_encoder_s(story_sequence)\n",
        "input_encoded_q = input_encoder_q(story_sequence)\n",
        "question_encoded = question_encoder(question)\n",
        "\n",
        "# compute a 'match' between the first input vector sequence\n",
        "# and the question vector sequence\n",
        "# shape: `(samples, story_maxlen, question_maxlen)`\n",
        "match = dot([input_encoded_s, question_encoded], axes=(2, 2))\n",
        "match = Activation('softmax')(match)\n",
        "\n",
        "# add the match matrix with the second input vector sequence\n",
        "response = add([match, input_encoded_q])  # (samples, story_maxlen, question_maxlen)\n",
        "response = Permute((2, 1))(response)  # (samples, question_maxlen, story_maxlen)\n",
        "\n",
        "# concatenate the match matrix with the question vector sequence\n",
        "answer = concatenate([response, question_encoded])\n",
        "\n",
        "answer = LSTM(32)(answer)  # (samples, 32)\n",
        "answer = Dropout(0.3)(answer)\n",
        "answer = BatchNormalization()(answer)\n",
        "\n",
        "output = Dense(vocab_size)(answer)  # (samples, vocab_size)\n",
        "output = Activation('softmax')(output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "li3C4Nw8Fok7"
      },
      "source": [
        "model = Model([story_sequence, question], output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JsYYaLF0FsMO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de469c74-4759-4e9d-9022-d0f4127de75a"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_3 (InputLayer)            [(None, 68)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_4 (InputLayer)            [(None, 4)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "sequential_3 (Sequential)       (None, None, 64)     1408        input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "sequential_5 (Sequential)       (None, 4, 64)        1408        input_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dot (Dot)                       (None, 68, 4)        0           sequential_3[0][0]               \n",
            "                                                                 sequential_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 68, 4)        0           dot[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "sequential_4 (Sequential)       (None, None, 4)      88          input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "add (Add)                       (None, 68, 4)        0           activation[0][0]                 \n",
            "                                                                 sequential_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "permute (Permute)               (None, 4, 68)        0           add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 4, 132)       0           permute[0][0]                    \n",
            "                                                                 sequential_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     (None, 32)           21120       concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_6 (Dropout)             (None, 32)           0           lstm[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 32)           128         dropout_6[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 22)           726         batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 22)           0           dense[0][0]                      \n",
            "==================================================================================================\n",
            "Total params: 24,878\n",
            "Trainable params: 24,814\n",
            "Non-trainable params: 64\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cpmqf7FXFvuB"
      },
      "source": [
        "model.compile(optimizer=Adam(0.005), loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_PwUhvNDF5Xy"
      },
      "source": [
        "model.fit([inputs_train, questions_train], answers_train,\n",
        "          batch_size=128,\n",
        "          epochs=120,\n",
        "          validation_data=([inputs_test, questions_test], answers_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M8xZZNquQhQq"
      },
      "source": [
        "pred = model.predict(([inputs_test, questions_test]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7CdQXKJTQhyX"
      },
      "source": [
        "n = np.random.randint(0,1000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aZQEsrIhQn9c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "daa9f3c4-22bf-4cdc-fa0e-e662eb3f7721"
      },
      "source": [
        "story_list = test_stories[n][0]\n",
        "story =' '.join(word for word in story_list)\n",
        "print(\"Story is:\",story)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Story is: Daniel went to the bathroom . John went to the garden . John went back to the bedroom . Mary journeyed to the office . Daniel moved to the kitchen . John journeyed to the office . Mary journeyed to the kitchen . Sandra travelled to the bathroom .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I_40xvggQ0Iu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05fdf24f-9ba7-4062-90dc-9b23f0856cc2"
      },
      "source": [
        "question_list = test_stories[n][1]\n",
        "question =' '.join(word for word in question_list)\n",
        "print(\"Question is: \", question)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Question is:  Where is John ?\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IbgR73oLQ72-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b2f5eb5-4830-42a5-89f2-b235470c5fb4"
      },
      "source": [
        "answer = test_stories[n][2]\n",
        "print(\"Actual answer is: \", answer)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Actual answer is:  office\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2QVVuVs2Q97Q"
      },
      "source": [
        "max_value = np.argmax(pred[n])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-4TEly9dRE_g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a51d822-5a2f-4291-e4a6-afc18af93642"
      },
      "source": [
        "for key, val in word2id.items():\n",
        "    if val == max_value:\n",
        "        k = key\n",
        "h\n",
        "print(\"Machine answer is: \", k)\n",
        "print(\"Machine says: I am \", pred[n][max_value], \"certain of it\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Machine answer is:  the\n",
            "Machine says: I am  0.05471424 certain of it\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jVEcfnJwSbGE"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}